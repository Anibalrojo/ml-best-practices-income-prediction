{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.0 - Regularized Regression Analysis\n",
        "\n",
        "## Objective\n",
        "\n",
        "This notebook explores the effect of regularization on linear models. Unlike the other notebooks, this one treats the income prediction task as a **regression problem** (predicting a continuous value between 0 and 1) rather than a classification problem.\n",
        "\n",
        "This allows us to analyze how `Ridge (L2)`, `Lasso (L1)`, and `ElasticNet` regularization techniques affect the model coefficients and feature selection. The goal here is less about achieving the highest performance and more about **interpreting model behavior**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(os.path.join(os.path.abspath(''), '..', 'src'))\n",
        "\n",
        "from data.make_dataset import load_data\n",
        "from features.build_features import split_features_target, one_hot_encode_features, split_data\n",
        "\n",
        "# Models for this notebook\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n",
        "\n",
        "Load the data and apply `One-Hot Encoding` to prepare it for the linear regression models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = load_data('../data/processed/adult_cleaned.csv')\n",
        "X, y = split_features_target(df)\n",
        "\n",
        "X_ohe = one_hot_encode_features(X)\n",
        "X_train, X_test, y_train, y_test = split_data(X_ohe, y)\n",
        "\n",
        "print(\"Data prepared for linear regression.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train and Evaluate Regularized Models\n",
        "\n",
        "We will train three different regularized linear models and compare their performance using Mean Squared Error (MSE).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "lin_reg = LinearRegression()\n",
        "ridge = Ridge(alpha=1.0, random_state=42)\n",
        "lasso = Lasso(alpha=0.001, random_state=42) # Using a smaller alpha for Lasso to prevent it from zeroing out all coefficients\n",
        "elastic = ElasticNet(alpha=0.001, l1_ratio=0.5, random_state=42)\n",
        "\n",
        "# Train models\n",
        "lin_reg.fit(X_train, y_train)\n",
        "ridge.fit(X_train, y_train)\n",
        "lasso.fit(X_train, y_train)\n",
        "elastic.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "lin_reg_pred = lin_reg.predict(X_test)\n",
        "ridge_pred = ridge.predict(X_test)\n",
        "lasso_pred = lasso.predict(X_test)\n",
        "elastic_pred = elastic.predict(X_test)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_lin_reg = mean_squared_error(y_test, lin_reg_pred)\n",
        "mse_ridge = mean_squared_error(y_test, ridge_pred)\n",
        "mse_lasso = mean_squared_error(y_test, lasso_pred)\n",
        "mse_elastic = mean_squared_error(y_test, elastic_pred)\n",
        "\n",
        "# Display results\n",
        "print(\"MSE on Test Set:\")\n",
        "print(f\"Linear Regression (Unregularized): {mse_lin_reg:.4f}\")\n",
        "print(f\"Ridge Regression (L2):             {mse_ridge:.4f}\")\n",
        "print(f\"Lasso Regression (L1):             {mse_lasso:.4f}\")\n",
        "print(f\"Elastic Net (L1+L2):               {mse_elastic:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Coefficient Analysis\n",
        "\n",
        "The primary goal of this notebook is to see how regularization affects the model coefficients. We will extract the coefficients from each model and compare them.\n",
        "\n",
        "- **Lasso (L1)** is expected to drive many coefficients to exactly zero, performing feature selection.\n",
        "- **Ridge (L2)** is expected to shrink coefficients towards zero, but not completely eliminate them.\n",
        "- **ElasticNet** should provide a balance between the two.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature names from the OHE transformer\n",
        "feature_names = X_ohe.columns\n",
        "\n",
        "# Create a DataFrame to hold the coefficients\n",
        "coef_df = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"LinearRegression\": lin_reg.coef_,\n",
        "    \"Ridge\": ridge.coef_,\n",
        "    \"Lasso\": lasso.coef_,\n",
        "    \"ElasticNet\": elastic.coef_\n",
        "})\n",
        "\n",
        "# How many coefficients are zero?\n",
        "print(\"Number of coefficients set to zero:\")\n",
        "print(f\"Lasso: {(coef_df['Lasso'] == 0).sum()} / {len(coef_df)}\")\n",
        "print(f\"ElasticNet: {(coef_df['ElasticNet'] == 0).sum()} / {len(coef_df)}\")\n",
        "\n",
        "# Display the top 10 largest coefficients by magnitude for Linear Regression\n",
        "print(\"\\nTop 10 Linear Regression Coefficients (by magnitude):\")\n",
        "coef_df.reindex(coef_df.LinearRegression.abs().sort_values(ascending=False).index).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting the coefficients\n",
        "# Get top 20 features by Linear Regression coefficient magnitude\n",
        "top_features = coef_df.reindex(coef_df.LinearRegression.abs().sort_values(ascending=False).index).head(20)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(y='Feature', x='LinearRegression', data=top_features, color='gray', label='LinearRegression')\n",
        "sns.barplot(y='Feature', x='Ridge', data=top_features, color='blue', label='Ridge')\n",
        "sns.barplot(y='Feature', x='ElasticNet', data=top_features, color='green', label='ElasticNet')\n",
        "sns.barplot(y='Feature', x='Lasso', data=top_features, color='red', label='Lasso')\n",
        "plt.title('Comparison of Top 20 Coefficients')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.legend()\n",
        "plt.savefig('../reports/figures/3.0_coefficient_comparison.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
