{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.0 - Baseline Model Comparison\n",
        "\n",
        "## Objective\n",
        "\n",
        "This notebook establishes baseline performance for the income prediction task. It compares a simple linear model (`ElasticNet`) against a standard ensemble model (`RandomForest`) to set a benchmark for more complex models.\n",
        "\n",
        "This notebook will use the centralized scripts from the `src/` directory for:\n",
        "- Data loading (`src/data/make_dataset.py`)\n",
        "- Feature engineering (`src/features/build_features.py`)\n",
        "- Model training and evaluation (`src/models/train_model.py`)\n",
        "- Visualization (`src/visualization/visualize.py`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add src to path to allow imports\n",
        "sys.path.append(os.path.join(os.path.abspath(''), '..', 'src'))\n",
        "\n",
        "from data.make_dataset import load_data\n",
        "from features.build_features import (\n",
        "    split_features_target,\n",
        "    label_encode_features,\n",
        "    one_hot_encode_features,\n",
        "    split_data\n",
        ")\n",
        "from models.train_model import train_and_evaluate, save_model\n",
        "from visualization.visualize import plot_model_evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n",
        "\n",
        "Load the cleaned dataset from the `data/processed` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = load_data('../data/processed/adult_cleaned.csv')\n",
        "X, y = split_features_target(df)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ElasticNet (Baseline Linear Model)\n",
        "\n",
        "First, we'll train a regularized linear model. This requires `One-Hot Encoding` for the categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for linear models\n",
        "X_ohe = one_hot_encode_features(X)\n",
        "X_train_ohe, X_test_ohe, y_train, y_test = split_data(X_ohe, y)\n",
        "\n",
        "# Train and evaluate\n",
        "model_en, metrics_en = train_and_evaluate(X_train_ohe, y_train, X_test_ohe, y_test, \"ElasticNet\")\n",
        "\n",
        "print(\"ElasticNet Performance:\")\n",
        "print(pd.Series(metrics_en))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_model_evaluation(y_test, model_en, X_test_ohe, \"ElasticNet\", save_path_prefix='../reports/figures/1.0_elasticnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Random Forest (Baseline Ensemble Model)\n",
        "\n",
        "Now, we'll train a `Random Forest` model. This is a robust ensemble method that can serve as a strong baseline. We will use `Label Encoding` for this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for tree-based models\n",
        "X_le = label_encode_features(X)\n",
        "X_train_le, X_test_le, y_train, y_test = split_data(X_le, y)\n",
        "\n",
        "# Train and evaluate\n",
        "model_rf, metrics_rf = train_and_evaluate(X_train_le, y_train, X_test_le, y_test, \"RandomForest\")\n",
        "\n",
        "print(\"Random Forest Performance:\")\n",
        "print(pd.Series(metrics_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_model_evaluation(y_test, model_rf, X_test_le, \"Random Forest\", save_path_prefix='../reports/figures/1.0_randomforest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Conclusion\n",
        "\n",
        "Let's compare the performance of the two baseline models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataFrame for comparison\n",
        "results_df = pd.DataFrame({\n",
        "    \"ElasticNet\": metrics_en,\n",
        "    \"RandomForest\": metrics_rf\n",
        "}).round(4)\n",
        "\n",
        "print(\"Baseline Model Comparison:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Best Baseline Model\n",
        "\n",
        "Based on the `ROC-AUC` score, we will select the best performing model from this baseline comparison and save it. This model will serve as the benchmark for the more advanced models in the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the save path relative to the notebook's location\n",
        "models_dir = '../models/'\n",
        "\n",
        "# Determine the best model\n",
        "if metrics_rf['ROC-AUC'] > metrics_en['ROC-AUC']:\n",
        "    best_baseline_model = model_rf\n",
        "    model_name = \"RandomForest\"\n",
        "else:\n",
        "    best_baseline_model = model_en\n",
        "    model_name = \"ElasticNet\"\n",
        "\n",
        "print(f\"Best baseline model is: {model_name} with ROC-AUC of {results_df.loc['ROC-AUC', model_name]}\")\n",
        "\n",
        "# Construct the full path and save the model\n",
        "save_path = os.path.join(models_dir, 'baseline_model.joblib')\n",
        "save_model(best_baseline_model, save_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
